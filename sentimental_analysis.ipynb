{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8hMLY6chxUetZSimUqDyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-12/sentiment_analysis-of-web-scrapped-data/blob/main/sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!pip install webdriver-manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpbjNBXOUSmA",
        "outputId": "bc3578e3-46cc-4a18-8da1-c6ddcba69201"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.10.0-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.15)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9 (from trio~=0.17->selenium)\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed async-generator-1.10 h11-0.14.0 outcome-1.2.0 selenium-4.10.0 trio-0.22.0 trio-websocket-0.10.3 wsproto-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-3.8.6-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (2.27.1)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (3.4)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.0.0 webdriver-manager-3.8.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jBnuy-C3_0Uh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from webdriver_manager.chrome import ChromeDriverManager"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "links=pd.read_excel('Input.xlsx')\n",
        "links.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "ZKLN6lDzFsMZ",
        "outputId": "2d3ae689-7d17-4453-fd28-0e0ba85c3374"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9cf5e1d214ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Input.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "dILUXaiqiE0O",
        "outputId": "bf3acf46-ae76-4088-9848-5e362ffb0e7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "driver =ChromeDriverManager().install()\n",
        "\n"
      ],
      "metadata": {
        "id": "5-QyUX_GGBsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04405a70-40d7-4a66-babb-85c4a2fb85ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[WDM] - Downloading: 100%|██████████| 7.06M/7.06M [00:00<00:00, 217MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_data(link):\n",
        "  global driver\n",
        "  driver.get(link)\n",
        "  title= driver.find_element(By.XPATH,\"//div[contains(@class,'td-post-content')]\")\n",
        "  driver.implicity_wait(10)\n",
        "  return title.text"
      ],
      "metadata": {
        "id": "bxRHHptPTmvo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(scrapdata):\n",
        "  for data in scrapdata:\n",
        "    name=str(data['URL_ID'])+\".txt\"\n",
        "    f=open(\"./Articles/\"+name,'w+',encoding='utf-8')\n",
        "    f.write(data['TEXT'])\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "wPtkWGSbW26-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performing Scraping"
      ],
      "metadata": {
        "id": "xxxWg78-aYRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "\n",
        "for index, row in links.iterrows():\n",
        "  item={}\n",
        "  item['URL_ID']=row['URL_ID']\n",
        "  item['TEXT']=scrape_data(row['URL'])\n",
        "  scrapdata.append(element)\n",
        "save_file(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "A59kSlrUaGLY",
        "outputId": "ab3ba6b2-fc84-4f97-ab0d-68562f335bbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a2da8799fbff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'URL_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'URL_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'links' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "making a dataframe of scraped data"
      ],
      "metadata": {
        "id": "WYFkr8AaGBgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "path='files'\n",
        "files= listdir(path)\n"
      ],
      "metadata": {
        "id": "0-FPsH54D6pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=pd.DataFrame(columns=[\"filename\",\"text\"])\n",
        "\n",
        "for file in files:\n",
        "  f= open(\"./files/\"+file,\"r\")\n",
        "  text= f.read()\n",
        "  sr= int(file.replace(\".0.txt\",\"\"))\n",
        "\n",
        "  df=df.append({\"File\":sr,\"Content\":text},ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "a77WEuBwE7pu",
        "outputId": "3d410688-7fd0-4122-b573-45c2fda8e8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ec66fb35471f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./files/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".0.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xbb in position 10: invalid start byte"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.sort_values(\"File\")\n",
        "df\n",
        "df.to_csv(\"content.csv\",index=None)"
      ],
      "metadata": {
        "id": "kSuxbcjCFHZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('content.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GDD2B33rf0eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data preprocessing"
      ],
      "metadata": {
        "id": "4yFo9h9ahbfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Number of sentences\"]=df['text'].apply(lambda x: len(x.split('.')))"
      ],
      "metadata": {
        "id": "BOohpEdEgLGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   def short_forms():\n",
        "        return {\\n\",\n",
        "            \\\"cant\\\":\\\"can not\\\",\\n\"\n",
        "            \\\"dont\\\":\\\"do not\\\",\\n\"\n",
        "            \\\"wont\\\":\\\"will not\\\",\\n\"\n",
        "            \\\"ain't\\\":\\\"is not\\\",\\n\"\n",
        "            \\\"amn't\\\":\\\"am not\\\",\\n\"\n",
        "            \\\"aren't\\\":\\\"are not\\\",\\n\"\n",
        "            \\\"can't\\\":\\\"cannot\\\",\\n\"\n",
        "            \\\"'cause\\\":\\\"because\\\",\\n\"\n",
        "           \\\"couldn't\\\":\\\"could not\\\",\\n\"\n",
        "            \\\"couldn't've\\\":\\\"could not have\\\",\\n\"\n",
        "            \\\"could've\\\":\\\"could have\\\",\\n\"\n",
        "            \\\"daren't\\\":\\\"dare not\\\",\\n\"\n",
        "\n",
        "            \\\"daresn't\\\":\\\"dare not\\\",\\n\"\n",
        "           \\\"dasn't\\\":\\\"dare not\\\",\\n\",\n",
        "           \\\"didn't\\\":\\\"did not\\\",\\n\",\n",
        "           \\\"doesn't\\\":\\\"does not\\\",\\n\",\n",
        "           \\\"don't\\\":\\\"do not\\\",\\n\",\n",
        "           \\\"e'er\\\":\\\"ever\\\",\\n\",\n",
        "           \\\"em\\\":\\\"them\\\",\\n\",\n",
        "           \\\"everyone's\\\":\\\"everyone is\\\",\\n\",\n",
        "           \\\"finna\\\":\\\"fixing to\\\",\\n\",\n",
        "           \\\"gimme\\\":\\\"give me\\\",\\n\",\n",
        "           \\\"gonna\\\":\\\"going to\\\",\\n\",\n",
        "           \\\"gon't\\\":\\\"go not\\\",\\n\",\n",
        "           \\\"gotta\\\":\\\"got to\\\",\\n\",\n",
        "           \\\"hadn't\\\":\\\"had not\\\",\\n\",\n",
        "           \\\"hasn't\\\":\\\"has not\\\",\\n\",\n",
        "           \\\"haven't\\\":\\\"have not\\\",\\n\",\n",
        "           \\\"he'd\\\":\\\"he would\\\",\\n\",\n",
        "           \\\"he'll\\\":\\\"he will\\\",\\n\",\n",
        "           \\\"he's\\\":\\\"he is\\\",\\n\",\n",
        "           \\\"he've\\\":\\\"he have\\\",\\n\",\n",
        "           \\\"how'd\\\":\\\"how would\\\",\\n\",\n",
        "           \\\"how'll\\\":\\\"how will\\\",\\n\",\n",
        "           \\\"how're\\\":\\\"how are\\\",\\n\",\n",
        "           \\\"how's\\\":\\\"how is\\\",\\n\",\n",
        "           \\\"I'd\\\":\\\"I would\\\",\\n\",\n",
        "           \\\"I'll\\\":\\\"I will\\\",\\n\",\n",
        "           \\\"I'm\\\":\\\"I am\\\",\\n\",\n",
        "           \\\"I'm'a\\\":\\\"I am about to\\\",\\n\",\n",
        "           \\\"I'm'o\\\":\\\"I am going to\\\",\\n\",\n",
        "           \\\"isn't\\\":\\\"is not\\\",\\n\",\n",
        "           \\\"it'd\\\":\\\"it would\\\",\\n\",\n",
        "           \\\"it'll\\\":\\\"it will\\\",\\n\",\n",
        "           \\\"it's\\\":\\\"it is\\\",\\n\",\n",
        "           \\\"I've\\\":\\\"I have\\\",\\n\",\n",
        "           \\\"kinda\\\":\\\"kind of\\\",\\n\",\n",
        "           \\\"let's\\\":\\\"let us\\\",\\n\",\n",
        "           \\\"mayn't\\\":\\\"may not\\\",\\n\",\n",
        "           \\\"may've\\\":\\\"may have\\\",\\n\",\n",
        "           \\\"mightn't\\\":\\\"might not\\\",\\n\",\n",
        "           \\\"might've\\\":\\\"might have\\\",\\n\",\n",
        "           \\\"mustn't\\\":\\\"must not\\\",\\n\",\n",
        "           \\\"mustn't've\\\":\\\"must not have\\\",\\n\",\n",
        "           \\\"must've\\\":\\\"must have\\\",\\n\",\n",
        "           \\\"needn't\\\":\\\"need not\\\",\\n\",\n",
        "           \\\"ne'er\\\":\\\"never\\\",\\n\",\n",
        "           \\\"o'\\\":\\\"of\\\",\\n\",\n",
        "     \\\"o'er\\\":\\\"over\\\",\\n\",\n",
        "         \\\"ol'\\\":\\\"old\\\",\\n\",\n",
        "         \\\"oughtn't\\\":\\\"ought not\\\",\\n\",\n",
        "          \\\"shalln't\\\":\\\"shall not\\\",\\n\",\n",
        "          \\\"shan't\\\":\\\"shall not\\\",\\n\",\n",
        "         \\\"she'd\\\":\\\"she would\\\",\\n\",\n",
        "         \\\"she'll\\\":\\\"she will\\\",\\n\",\n",
        "         \\\"she's\\\":\\\"she is\\\",\\n\",\n",
        "         \\\"shouldn't\\\":\\\"should not\\\",\\n\",\n",
        "         \\\"shouldn't've\\\":\\\"should not have\\\",\\n\",\n",
        "         \\\"should've\\\":\\\"should have\\\",\\n\",\n",
        "         \\\"somebody's\\\":\\\"somebody is\\\",\\n\",\n",
        "         \\\"someone's\\\":\\\"someone is\\\",\\n\",\n",
        "         \\\"something's\\\":\\\"something is\\\",\\n\",\n",
        "         \\\"that'd\\\":\\\"that would\\\",\\n\",\n",
        "         \\\"that'll\\\":\\\"that will\\\",\\n\",\n",
        "         \\\"that're\\\":\\\"that are\\\",\\n\",\n",
        "         \\\"that's\\\":\\\"that is\\\",\\n\",\n",
        "         \\\"there'd\\\":\\\"there would\\\",\\n\",\n",
        "         \\\"there'll\\\":\\\"there will\\\",\\n\",\n",
        "         \\\"there're\\\":\\\"there are\\\",\\n\",\n",
        "         \\\"there's\\\":\\\"there is\\\",\\n\",\n",
        "          \\\"these're\\\":\\\"these are\\\",\\n\",\n",
        "         \\\"they'd\\\":\\\"they would\\\",\\n\",\n",
        "         \\\"they'll\\\":\\\"they will\\\",\\n\",\n",
        "         \\\"they're\\\":\\\"they are\\\",\\n\",\n",
        "         \\\"they've\\\":\\\"they have\\\",\\n\",\n",
        "         \\\"this's\\\":\\\"this is\\\",\\n\",\n",
        "         \\\"those're\\\":\\\"those are\\\",\\n\",\n",
        "         \\\"'tis\\\":\\\"it is\\\",\\n\",\n",
        "         \\\"'twas\\\":\\\"it was\\\",\\n\",\n",
        "         \\\"wanna\\\":\\\"want to\\\",\\n\",\n",
        "         \\\"wasn't\\\":\\\"was not\\\",\\n\",\n",
        "         \\\"we'd\\\":\\\"we would\\\",\\n\",\n",
        "         \\\"we'd've\\\":\\\"we would have\\\",\\n\",\n",
        "         \\\"we'll\\\":\\\"we will\\\",\\n\",\n",
        "          \\\"we're\\\":\\\"we are\\\",\\n\",\n",
        "         \\\"weren't\\\":\\\"were not\\\",\\n\",\n",
        "         \\\"we've\\\":\\\"we have\\\",\\n\",\n",
        "         \\\"what'd\\\":\\\"what did\\\",\\n\",\n",
        "         \\\"what'll\\\":\\\"what will\\\",\\n\",\n",
        "         \\\"what're\\\":\\\"what are\\\",\\n\",\n",
        "         \\\"what's\\\":\\\"what is\\\",\\n\",\n",
        "           \\\"what've\\\":\\\"what have\\\",\\n\",\n",
        "           \\\"when's\\\":\\\"when is\\\",\\n\",\n",
        "           \\\"where'd\\\":\\\"where did\\\",\\n\",\n",
        "          \\\"where're\\\":\\\"where are\\\",\\n\",\n",
        "           \\\"where's\\\":\\\"where is\\\",\\n\",\n",
        "           \\\"where've\\\":\\\"where have\\\",\\n\",\n",
        "           \\\"which's\\\":\\\"which is\\\",\\n\",\n",
        "           \\\"who'd\\\":\\\"who would\\\",\\n\",\n",
        "           \\\"who'd've\\\":\\\"who would have\\\",\\n\",\n",
        "           \\\"who'll\\\":\\\"who will\\\",\\n\",\n",
        "           \\\"who're\\\":\\\"who are\\\",\\n\",\n",
        "           \\\"who's\\\":\\\"who is\\\",\\n\",\n",
        "           \\\"who've\\\":\\\"who have\\\",\\n\",\n",
        "         \\\"why'd\\\":\\\"why did\\\",\\n\",\n",
        "           \\\"why're\\\":\\\"why are\\\",\\n\",\n",
        "           \\\"why's\\\":\\\"why is\\\",\\n\",\n",
        "           \\\"won't\\\":\\\"will not\\\",\\n\",\n",
        "        \\\"wouldn't\\\":\\\"would not\\\",\\n\",\n",
        "        \\\"would've\\\":\\\"would have\\\",\\n\",\n",
        "        \\\"y'all\\\":\\\"you all\\\",\\n\",\n",
        "        \\\"you'd\\\":\\\"you would\\\",\\n\",\n",
        "        \\\"you'll\\\":\\\"you will\\\",\\n\",\n",
        "        \\\"you're\\\":\\\"you are\\\",\\n\",\n",
        "        \\\"you've\\\":\\\"you have\\\",\\n\",\n",
        "      \\\"Whatcha\\\":\\\"What are you\\\",\\n\",\n",
        "        \\\"luv\\\":\\\"love\\\",\\n\",\n",
        "        \\\"sux\\\":\\\"sucks\\\",\\n\",\n",
        "        \\\"couldn't\\\":\\\"could not\\\",\\n\",\n",
        "        \\\"wouldn't\\\":\\\"would not\\\",\\n\",\n",
        "        \\\"shouldn't\\\":\\\"should not\\\",\\n\",\n",
        "        \\\"im\\\":\\\"i am\\\"\\n\",\n",
        "        }\""
      ],
      "metadata": {
        "id": "80Bl0f6Sh7ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    import re  ##check if a particular string matches a given regular expression\\n\",\n",
        "    import string\n",
        "\n",
        "    ## funtion to replace the short forms \\n\",\n",
        "    def normalization(data):\n",
        "        data = str(data).lower()\n",
        "        # URL\\n\",\n",
        "        data = re.sub('((www.[^\\\\s]+)|(https?://[^\\\\s]+))',' ',data)\n",
        "        data = re.sub(r'#([^\\\\s]+)', r'\\\\1', data)\n",
        "\n",
        "        # Number\\n\",\n",
        "        data = ''.join([i for i in data if not i.isdigit()])\n",
        "\n",
        "        # Punctuation\\n\",\n",
        "\n",
        "        for sym in string.punctuation:\n",
        "            data = data.replace(sym, \\\" \\\")\n",
        "       short_form = short_forms()\n",
        "        data = data.replace(\\\"’\\\",\\\"'\\\")\n",
        "        words = data.split()\n",
        "        converted = [short_form[word] if word in short_form else word for word in words]\n",
        "        data = \\\" \\\".join(converted)\n",
        "        return data"
      ],
      "metadata": {
        "id": "5qj9LItdjPuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "b38vKPysj_-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']=df['text'].apply(normalization)"
      ],
      "metadata": {
        "id": "-fUXvoY0kA-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zx43JRTSs4xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']= df['text'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "HPwYVOdys6Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "F_ErHunqkIGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "performing sentimental analysis"
      ],
      "metadata": {
        "id": "jw6qSB7BtTqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "guide =pd.read_csv('LoughranMcDonald_MusterDictionary_2020.csv')\n",
        "guide.head()"
      ],
      "metadata": {
        "id": "06lpxc8utWok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos=[]\n",
        "neg=[]\n",
        "Uncertain=[]\n",
        "for index,row in guide.iterrows():\n",
        "  if row['Negative']>0:\n",
        "    neg.append(row['Word'].lower())\n",
        "  elif row['Positive']>0:\n",
        "    pos.append(row['Word'].lower())\n",
        "  elif row['Uncertainity']>0:\n",
        "    Uncertain.append(row['Word'].lower())"
      ],
      "metadata": {
        "id": "ZwztUuNytrvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "c9jBHz1XuT-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positivescore(text):\n",
        "  score=0\n",
        "  global pos\n",
        "  words=text.split()\n",
        "  for word in words:\n",
        "    if word in pos:\n",
        "      score+=1\n",
        "  return score\n",
        "def negativescore(text):\n",
        "  score=0\n",
        "  global=neg\n",
        "  words=text.split()\n",
        "  for word in words:\n",
        "    if word in neg:\n",
        "      score +=1\n",
        "  return score"
      ],
      "metadata": {
        "id": "FX2A4fAPuV7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Positive Score']=df['text'].apply(positivescore)\n",
        "df['Negative Score']=df['text'].apply(negativescore)"
      ],
      "metadata": {
        "id": "E1juppDazLfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vjsTMJWE0kLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['POLARITY SCORE']=(df['Positive Score']-df['Negative Score'])/((df['Positive Score']+df['Negative Score'])+0.000001)\n",
        "df['WORD COUNT']= Df['text'].apply(lambda x:len(x.split()))\n",
        "df['SUBJECTIVITY SCORE']=(df['Positive Score']+df['Negative Score'])/((df['WORD COUNT'])+0.000001)\n",
        "df['AVERAGE SENTENCE LENGTH']= df['WORD COUNT']/df['NUMBER OF SENTENCES']\n",
        "df['AVG NUMBER OF WORDS PER SENTENCE']=df['WORD COUNT']/df['Number of sentences']"
      ],
      "metadata": {
        "id": "GUaq1MV70lwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "FXXNrjfr16hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avgwordlength(text):\n",
        "  words=text.split()\n",
        "  no_of_words=len(Words)\n",
        "  total_char=0\n",
        "  for word in words:\n",
        "    total_chars +=len(word)\n",
        "  return total_char/no_of_words"
      ],
      "metadata": {
        "id": "Lc-kGWiA2an7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pronoun(text):\n",
        "  pronouns=r\"(\\b(s?i|me|we|we|my|ours|us|I|Me|My|Ours|Us)\\b)\"\n",
        "  result=0\n",
        "\n",
        "  matches =re.finditer(pronouns,text,re.MULTILINE)\n",
        "  for nummatch,match in enumerate(matches):\n",
        "    result+=1\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "ES73YIHd2y9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AVG WORD LENGTH']=df['TEXT'].apply(avgwordlength)\n",
        "df['AVG SENTENCE LENGTH']=df['WORD COUNT']/df['Number of sentences']\n",
        "df['PERSONAL PRONOUNS']=df['text'].apply(pronoun)"
      ],
      "metadata": {
        "id": "az-aiwff3aPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head( )"
      ],
      "metadata": {
        "id": "2mvxmIv93zZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['URL']=links['URL']\n",
        "df.columns"
      ],
      "metadata": {
        "id": "ebVmL-zE5QER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df['URL','filename','text','Number of sentences','Positive Score','Negative Score','POLARITY SCORE','WORD COUNT','SUBJECTIVITY SCORE','AVERAGE SENTENCE LENGTH','AVG NUMBER OF WORDS PER SENTENCE','AVG WORD LENGTH',\n",
        "      'AVG SENTENCE LENGTH','PERSONAL PRONOUNS','URL'],\n",
        "      dtype='objects'"
      ],
      "metadata": {
        "id": "Bxty_Unn5WlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "6u0DAwvq6O7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}